{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2237ca2b-443d-4d83-ab28-752d5ee60d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "# !pip install category_encoders\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d752b4b8-3bea-41c1-88ca-a94140e9d00e",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a17589-b7b7-48d8-948a-fcba8b10afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データロード\n",
    "df = pd.read_csv('./workspace/vgsales.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d23dd12-3efb-4706-a90e-cdff862609ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b552203f-a83b-42ac-9f67-56d124e54c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearの欠損数\n",
    "len(df[df['Year'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e412263-ebbb-49e3-b8ab-140dd0ad12e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publisherが欠損しているレコードのindex\n",
    "pub_na_idx = df[df['Publisher'].isna()].index\n",
    "# Yearが欠損しているレコードのindex\n",
    "year_na_idx = df[df['Year'].isna()].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1fa89-014d-4095-8ad2-de4fa937181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publisherの欠損を\"NaN\"で埋める\n",
    "df[['Publisher']] = df[['Publisher']].fillna(\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4e6ead-6e94-41b7-89dd-656457d04796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 複数のカラムを同時に埋めることも可能\n",
    "df = pd.read_csv('./workspace/vgsales.csv')\n",
    "df.fillna({'Publisher': \"NaN\", 'Year': df['Year'].median()}, inplace=True)\n",
    "df.iloc[year_na_idx][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458adb6-d70e-4f10-a50e-723aa94cc179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publisherの欠損とUnkownの分布の違いを確認\n",
    "pub_nan_df = df[df['Publisher']=='NaN']\n",
    "pub_unknown_df = df[df['Publisher']=='Unknown']\n",
    "pub_missing_df = pd.concat([pub_nan_df, pub_unknown_df])\n",
    "sns.pairplot(pub_missing_df, hue='Publisher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670ea6fa-c972-4a1f-9792-082f4118c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleImputerでも欠損値代入が可能\n",
    "# Yearに中央値，Publisherには最頻値を入れる例\n",
    "df = pd.read_csv('./workspace/vgsales.csv')\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df['Year'] = imputer.fit_transform(df[['Year']])\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "# from IPython.display import display\n",
    "# display(imputer.fit_transform(df[['Publisher']]))\n",
    "# df['Publisher'] = imputer.fit_transform(df[['Publisher']])\n",
    "df[['Publisher']] = imputer.fit_transform(df[['Publisher']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a4e8cb-5829-49d0-b4fc-30e3e9e25d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Platform別にYearの中央値を計算し，その値で欠損値を埋める\n",
    "df = pd.read_csv('./workspace/vgsales.csv')\n",
    "platform_year_dict = df.groupby('Platform')['Year'].median().to_dict()\n",
    "df['Year'] = df.apply(\n",
    "    lambda row: platform_year_dict[row['Platform']] if row['Year'] in platform_year_dict and np.isnan(row['Year']) else row['Year'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b32df1b-d79c-47b1-802e-66661135fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれのPlatformに対応してYearの値が入っている\n",
    "df.iloc[year_na_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad05ff-feba-4626-8447-275b1c7a478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 代表値による欠損代入する場合，代表値は学習データを使用して計算する\n",
    "df = pd.read_csv('./workspace/vgsales.csv')\n",
    "df.drop('Global_Sales', inplace=True, axis=1) # Global_Salesがあると簡単にJP_Salesを計算できてしまうため\n",
    "target = 'JP_Sales'\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "platform_year_dict = X_train.groupby('Platform')['Year'].median().to_dict()\n",
    "X_train['Year'] = X_train.apply(\n",
    "    lambda row: platform_year_dict[row['Platform']] if np.isnan(row['Year']) and row['Platform'] in platform_year_dict else row['Year'],\n",
    "    axis=1\n",
    ")\n",
    "# テストデータにも同様にplatform_year_dictを使用する\n",
    "X_test['Year'] = X_test.apply(\n",
    "    lambda row: platform_year_dict[row['Platform']] if np.isnan(row['Year']) and row['Platform'] in platform_year_dict else row['Year'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387de634-0798-4d63-919a-482a26a5a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c13c5b5-1e9a-43b1-9fa0-9ece1871de89",
   "metadata": {},
   "source": [
    "### kNNで欠損値代入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879366b9-665a-48ae-add9-ce7ac1f8fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ準備\n",
    "df = pd.read_csv('./workspace/vgsales.csv')\n",
    "# 欠損値をNaNで補完\n",
    "df[['Publisher']] = \n",
    "df.drop(\"Name\", inplace=True, axis=1)\n",
    "# Yearカラムの欠損をKNNで代入する\n",
    "target = \"Year\"\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "# 数値カラムのリスト取得(標準化の対象)\n",
    "num_cols = \n",
    "# ダミー変数\n",
    "X = \n",
    "# 標準化\n",
    "\"\"\"\n",
    "Xに本来の予測する対象データが含まれている場合,train_test_splitで分割し,\n",
    "train_Xに対してStandardScalerを適用する\n",
    "\"\"\"\n",
    "X[num_cols] = \n",
    "# YearがNaNのデータはテストデータ，そうでなければ学習データ\n",
    "test_indexes = \n",
    "train_indexes = \n",
    "X_train, X_test = \n",
    "y_train, y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a9bba-692b-48dc-ac71-2c92036347b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNNのモデルを作って予測値を代入する\n",
    "knn = \n",
    "y_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb7c084-42f7-4642-a1d8-028d395c45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一つ目のテストデータのkNNのYear予測を確認\n",
    "df.iloc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5cdd7e-14cf-4956-b01a-750815dae167",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2bee5-2db3-444c-9231-9ee36c347fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighborとして使用されたデータを確認する\n",
    "neighbors = \n",
    "# neighbors[1][0]には，予測に使用されたデータのindexが格納されているが，このindexは学習データX_trainのindexであるため，\n",
    "# 一度reset_index()でindexを振り直して対象データにアクセスし，['index']カラムから元のdfのindexを取得する\n",
    "df.loc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14db3ee4-86c6-49b0-8ffb-d8e1f76567c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNNImputerを使う\n",
    "imputer = \n",
    "imputer.\n",
    "# ダミー変数\n",
    "df = \n",
    "# 標準化\n",
    "df[num_cols] = \n",
    "df_imputed = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931e236-235c-4a2b-b901-9aaf1e9d66d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed.iloc[test_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830fea97-55ee-453a-bb30-784519656a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNNImputerの結果とKNeighborsRegressorが等しいことを確認\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e643306-802a-4ee9-a017-6320a2bee27a",
   "metadata": {},
   "source": [
    "## 欠損値代入の比較"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09ff5555-8eb5-4c05-a8db-d22039943666",
   "metadata": {},
   "source": [
    "### データ準備とEDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e49114-aec3-462b-b594-08dec2cd9290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./workspace/penguins_size.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9c4f6-cd05-4171-8a17-e966403f6923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8df34b-4385-43d9-a3a1-0985465162e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.pairplot(df, hue='species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698805f-1ef3-410f-8271-9a493646258a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb960d-e6ce-4007-8cb0-9abfbdcd9fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリカルカラムのユニークな値とそれぞれの値にレコード数\n",
    "cat_cols = \n",
    "for cat_col in cat_cols:\n",
    "    print(f\"======{cat_col}======\")\n",
    "    print(df[cat_col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23ff167-a179-4e80-9898-68563ff1bf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \".\"は欠損値扱いにする\n",
    "df.loc[] = np.nan\n",
    "df[df['sex'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a7a62-919a-47bc-a6eb-ac4b2403c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれの結果を格納するディクショナリー\n",
    "results = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e454ff2-fd27-46f6-a256-4aadd70ca3ec",
   "metadata": {},
   "source": [
    "### 欠損値を落とすケース\n",
    "- .dropna()\n",
    "- モデルはなんでもOK(回答例ではロジスティック回帰を使用)\n",
    "- 5foldx3で評価\n",
    "- PipelineやColumnTransformerクラスを使用する\n",
    "- 評価指標はloglossを使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf6b337-e824-4d91-b2d9-ce969cfcc68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "target = 'species'\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "\n",
    "#　前処理\n",
    "# ダミー変数\n",
    "X = \n",
    "\n",
    "# CV\n",
    "k = 5\n",
    "n_repeats = 3\n",
    "cv = \n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = \n",
    "scores = \n",
    "results['drop'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a71235b-f652-42a8-ba40-01c7203262d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a1c2dd1-93aa-466f-872c-c92e19763169",
   "metadata": {},
   "source": [
    "### 欠損を新カテゴリーとする(カテゴリカル変数) and 中央値で代入(数値変数)\n",
    "- 欠損値を新しいカテゴリとしたケース(数値カラムは中央値で代入)\n",
    "- sklearn.impute.SimpleImputer() .fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31865793-c48c-469f-91c9-75d85418c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('penguins_size.csv')\n",
    "# \".\"は欠損値扱いにする\n",
    "df.loc[] = np.nan\n",
    "target = 'species'\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "\n",
    "# CV\n",
    "k = 5\n",
    "n_repeats = 3\n",
    "cv = \n",
    "\n",
    "# ダミー変数生成クラスを自作(Pipelineに組み込むため)\n",
    "class GetDummies(BaseEstimator, TransformerMixin):\n",
    "\n",
    "\n",
    "# PipelineはDataFrame全体に対しての処理\n",
    "# 数値columnのみに適用することができない\n",
    "# -> ColumnTransformer\n",
    "# Columns Transformer (imputer)\n",
    "num_cols = \n",
    "cat_cols = \n",
    "ct = \n",
    "\n",
    "# デフォルトだとColumnTransformerの結果がNumPyArrayになるが，\n",
    "# 後続処理で問題になることがあるのでDataFrameにする\n",
    "ct.\n",
    "\n",
    "# Pipeline (dummy + scaler + model)\n",
    "pipeline = \n",
    "scores = \n",
    "results['median'] = \n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adbc672d-f6a0-4594-a980-b9023d9813f3",
   "metadata": {},
   "source": [
    "### 欠損をkNNで予測したケース(カテゴリカルカラムは最頻値)\n",
    "- 欠損値をkNNで予測したケース(カテゴリカルカラムは最頻値で代入)\n",
    "- sklearn.impute.KNNImputer(n_neighbors).fit_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e17c77-d515-4de1-82db-d4e4075e54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('penguins_size.csv')\n",
    "# \".\"は欠損値扱いにする\n",
    "df.loc[] = np.nan\n",
    "target = 'species'\n",
    "X = df.drop(target, axis=1)\n",
    "y = df[target]\n",
    "\n",
    "# CV\n",
    "k = 5\n",
    "n_repeats = 3\n",
    "cv = \n",
    "\n",
    "# ダミー変数生成クラスを自作(Pipelineに組み込むため)\n",
    "class GetDummies(BaseEstimator, TransformerMixin):\n",
    "\n",
    "# Columns Transformer (imputer)\n",
    "# num_cols = X.select_dtypes(include=np.number).columns.to_list()\n",
    "# cat_cols = X.select_dtypes(exclude=np.number).columns.to_list()\n",
    "num_pipeline = \n",
    "ct = \n",
    "ct.\n",
    "\n",
    "# Pipeline (dummy + scaler + model)\n",
    "pipeline = \n",
    "scores = \n",
    "results['knn'] = \n",
    "results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7ead34a-4073-427b-9986-50651c635d2b",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc0f215-637a-4984-ac94-d4ec264f3e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('penguins_size.csv')\n",
    "oe = \n",
    "oe.\n",
    "cat_cols = \n",
    "df[cat_cols] = \n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8f8e28f-602e-4a29-b7a8-d7ad0d52b19b",
   "metadata": {},
   "source": [
    "## Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece995b-6023-46cd-829c-f1e55b101c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('titanic')\n",
    "df.dropna(inplace=True)\n",
    "# adult_maleのデータタイプをobjectに変更し，target encodingの対象とする(実際にはaloneも同様に行う\n",
    "df['adult_male'] = \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c6241-f6a2-4c11-a6d5-5f97bfa5cbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = \n",
    "encoder.\n",
    "encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c03f741-30c6-45e4-8221-613b6cdb9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# マルチクラスのケース\n",
    "df = pd.read_csv('penguins_size.csv')\n",
    "df.loc[] = np.nan\n",
    "targets = df['species'].unique()\n",
    "for target in targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04437d33-2310-43bd-82c7-125e724835e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46794bca-5008-4ef6-9b55-a1150386f752",
   "metadata": {},
   "source": [
    "## Target Encoding vs One Hot Encoding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4c1d6f3-ea5f-48c1-b433-56615e3a0051",
   "metadata": {},
   "source": [
    "### データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575714c9-bc37-41f6-94ee-692e5e6b91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sns.load_dataset('titanic')\n",
    "df.drop()\n",
    "\n",
    "# adlut_maleとaloneをカテゴリカル変数として扱うための処理を書く\n",
    "df[['adult_male', 'alone']] = \n",
    "\n",
    "X = df.drop('survived', axis=1)\n",
    "y = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c65a8-3d56-4e1e-abc1-aeb909773f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれの結果を格納\n",
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9865092-e67a-4ac6-ace1-31c28c45e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値代入->カテゴリカル変数のEncoding->標準化->モデル学習\n",
    "\n",
    "# 処理する対象が違うので，カテゴリカルカラムと数値カラムのリストを取得する\n",
    "cat_cols = \n",
    "num_cols = \n",
    "\n",
    "# 欠損値代入\n",
    "cat_imputer = \n",
    "num_imputer = \n",
    "ct = \n",
    "ct.\n",
    "\n",
    "# target encoding\n",
    "pipeline_te = \n",
    "\n",
    "# one hot encoding\n",
    "class GetDummies(BaseEstimator, TransformerMixin):\n",
    "   \n",
    "pipeline_ohe = \n",
    "\n",
    "cv = \n",
    "scores['target'] = \n",
    "scores['onehot'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a31d92c-3079-4c5d-a9ea-9900fdd80d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af18f445-f00b-4e08-8bf9-50ef10106455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果をboxplotで描画\n",
    "sns.boxplot()\n",
    "plt.xticks()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d75fcb-5e4b-42b5-9dac-5d7c4c3d51be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中央値比較\n",
    "print(np.median(scores['target']))\n",
    "print(np.median(scores['onehot']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4754000e-1876-4293-ab3e-e54d6cfca9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 平均値比較\n",
    "print(np.mean(scores['target']))\n",
    "print(np.mean(scores['onehot']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docker-ml-env",
   "language": "python",
   "name": "docker-ml-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
